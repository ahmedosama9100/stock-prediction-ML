# -*- coding: utf-8 -*-
"""GP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jFAG8l-G2nweyWA0qi2M-jnDvaVqt6Rz
"""

import pandas as pd
import numpy as np

datasentment = pd.read_csv('sentment.csv' , parse_dates=[1])

print (datasentment.head())

print(datasentment.shape)
print(datasentment.dtypes)

datasetstock = pd.read_csv('stockdata.csv',parse_dates=[0])
print(datasetstock.head())

print(datasetstock.shape)
print(datasetstock.dtypes)

mergedata = datasentment[['Date', 'Label', 'Subjectivity', 'Objectivity', 'Positive', 'Negative', 'Neutral']].merge(datasetstock, how='inner', on='Date', left_index=True)
#print (mergedata.shape)
#print (mergedata.head())
#print (mergedata.dtypes)

colnames =list (mergedata)
colnames.append(colnames.pop(colnames.index('Label')))
#mergedata = mergedata.ix[:, colnames]
#############mergedata.head()

mergedata['Volume']=mergedata['Volume'].astype(float)
mergedata.index = mergedata.index.sort_values()
mergedata.head()

md_copy = mergedata
md_copy = md_copy.replace(-1, np.NaN)
import missingno as msno
# Nullity or missing values by columns
msno.matrix(df=md_copy.iloc[:,2:39], figsize=(20, 14), color=(0.42, 0.1, 0.05))

print(mergedata.dtypes)
print(mergedata.count())

## handle NAN 
nan_list = ['Subjectivity', 'Objectivity', 'Positive', 'Negative', 'Neutral']
for col in nan_list:
    mergedata[col] = mergedata[col].fillna(mergedata[col].mean())
## for check 
### print (mergedata.count())

x=mergedata.loc[:,'Subjectivity':'Adj Close']
y=mergedata.loc[:,'Label']
validation_size = 0.20
train_size = int(len(x.index) * 0.7)
X_train, X_test = x.loc[0:train_size, :], x.loc[train_size: len(x.index), :]
y_train, y_test = y[0:train_size+1], y.loc[train_size: len(x.index)]
print(X_train)

#important_features = mergedata[['Low', "Neutral", 'Close', 'Objectivity', 'Date']]
from xgboost import XGBClassifier
import xgboost as xgb
Xi_train, Xi_test = x.loc[0:train_size, :], x.loc[train_size: len(x.index), :]
clf = XGBClassifier(n_estimators=500, max_depth=3)
clf.fit(Xi_train, y_train)
yi_pred = clf.predict(Xi_test)

from sklearn.metrics import accuracy_score
score = accuracy_score(y_test, yi_pred)
print("Score is "+ str(score))

from sklearn.decomposition import PCA
#Principal Component Analysis (PCA)
pca = PCA(n_components=3)
pca.fit(x)
transformed = pca.transform(x)

transformed.shape
print(type(transformed))

pca_df = pd.DataFrame(transformed)

X_train_pca, X_test_pca = pca_df.loc[0:train_size, :], pca_df.loc[train_size: len(x.index), :]

clf = XGBClassifier(n_estimators=500, max_depth=3)
clf.fit(X_train_pca, y_train)
y_pred_pca = clf.predict(X_test_pca)
score = accuracy_score(y_test, y_pred_pca)
#print ("done by karam all i have  ")
print("Score is "+ str(score))